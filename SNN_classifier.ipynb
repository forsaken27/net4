{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8t2qrFpKuoBAMAFwIWVTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forsaken27/net4/blob/main/SNN_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNN classifer for MNIST dataset"
      ],
      "metadata": {
        "id": "N55V8Cy5MSx7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gISOxhlzTJ_9",
        "outputId": "5f9c48d1-fe32-4c04-ba08-7943972276b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment2/'\n",
        "FOLDERNAME = 'SNN_classifier/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spikingjelly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3sboYslWtxk",
        "outputId": "3acd6665-d0b3-4725-ca81-dfbbcba96226"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->spikingjelly)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->spikingjelly) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->spikingjelly) (3.0.2)\n",
            "Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m880.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, spikingjelly\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 spikingjelly-0.0.0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from spikingjelly.activation_based import neuron, functional, surrogate, encoding, layer\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "sbD8qoBaaQjT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ubLtG_3FTMwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "            ])\n",
        "train_dataset = dset.MNIST(root='./drive/MyDrive/SNN_classifier/data', train=True, download=True, transform=transform)\n",
        "test_dataset = dset.MNIST(root='./drive/MyDrive/SNN_classifier/data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(train_dataset.data.shape)\n",
        "print(test_dataset.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8EOvtIETNol",
        "outputId": "a09be569-5ecc-4a86-8c42-d72f8e2a7b06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "  def forward(self, x):\n",
        "    return x.view(x.shape[0], -1)\n",
        "tau = 2.0\n",
        "learning_rate = 1e-3\n",
        "\n",
        "\n",
        "net_4 = nn.Sequential(\n",
        "    #(T, 64, 1, 28, 28)\n",
        "    Flatten(),                         # (B, 1*28*28)\n",
        "    layer.Linear(28*28, 100, bias=False),\n",
        "    neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()),\n",
        "    nn.Dropout(0.2),\n",
        "    layer.Linear(100, 10, bias=False),\n",
        "    neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan())\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(net_4.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "encoder = encoding.PoissonEncoder()\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "eEj-2ZV2dMf6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch import amp\n",
        "import torch.nn.functional as F\n",
        "scaler = amp.GradScaler('cuda')\n",
        "T = 30\n",
        "\n",
        "def train_net(T, epochs):\n",
        "  net_4.train()\n",
        "  for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    net_4.train()\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    train_samples = 0\n",
        "    for img, label in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      img = img.to(device)\n",
        "      label = label.to(device)\n",
        "      label_onehot = F.one_hot(label, 10).float()\n",
        "\n",
        "          # Mixed-precision training\n",
        "      if scaler is not None:\n",
        "        with amp.autocast('cuda'):\n",
        "          out_fr = 0.\n",
        "          # Run T time steps\n",
        "          for t in range(T):\n",
        "            encoded_img = encoder(img)\n",
        "            out_fr += net_4(encoded_img)\n",
        "          out_fr = out_fr / T\n",
        "          # out_fr is tensor whose shape is [batch_size, 10]\n",
        "          # The firing rate of 10 neurons in the output layer was recorded during the whole simulation period\n",
        "          loss = F.mse_loss(out_fr, label_onehot)\n",
        "          # The loss function is the MSE between the firing rate of the output layer and the true category.\n",
        "          # The loss function will cause the firing rate of the correct neuron in the output layer to approach 1 when the label i is given, and the firing rate of the other neurons to approach 0.\n",
        "        scaler.scale(loss).backward(retain_graph=True)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "      else:\n",
        "        out_fr = 0.\n",
        "        for t in range(T):\n",
        "          encoded_img = encoder(img)\n",
        "          out_fr += net_4(encoded_img)\n",
        "        out_fr = out_fr / T\n",
        "        loss = F.mse_loss(out_fr, label_onehot)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      train_samples += label.numel()\n",
        "\n",
        "      train_loss += loss.item() * label.numel()\n",
        "      # The correct rate is calculated as follows. The subscript i of the neuron with the highest firing rate in the output layer is considered as the result of classification.\n",
        "      train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
        "\n",
        "      # After optimizing the parameters, the state of the network should be reset because the neurons of the SNN have “memory”.\n",
        "      functional.reset_net(net_4)\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    print(f\"Train Loss: {train_loss / train_samples}\")\n",
        "    print(f\"Train Acc: {train_acc /  train_samples}\")\n",
        "    print(f\"Time: {time.time() - start_time}\")\n",
        "\n",
        "train_net(T, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L36kPUjg0qmi",
        "outputId": "5851f0ee-13d8-4ec0-8b07-478a6fc1251d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train Loss: 0.021236207398275534\n",
            "Train Acc: 0.8816\n",
            "Time: 100.16350102424622\n",
            "Epoch: 1\n",
            "Train Loss: 0.010012805598974227\n",
            "Train Acc: 0.9452833333333334\n",
            "Time: 96.05491185188293\n",
            "Epoch: 2\n",
            "Train Loss: 0.007879040757318339\n",
            "Train Acc: 0.9575333333333333\n",
            "Time: 94.27358913421631\n",
            "Epoch: 3\n",
            "Train Loss: 0.006639468543728193\n",
            "Train Acc: 0.9655166666666667\n",
            "Time: 96.61773729324341\n",
            "Epoch: 4\n",
            "Train Loss: 0.005814811121672392\n",
            "Train Acc: 0.9711666666666666\n",
            "Time: 97.08322596549988\n",
            "Epoch: 5\n",
            "Train Loss: 0.005279079673749705\n",
            "Train Acc: 0.9747\n",
            "Time: 94.7437355518341\n",
            "Epoch: 6\n",
            "Train Loss: 0.00480752413480853\n",
            "Train Acc: 0.9777333333333333\n",
            "Time: 95.9030168056488\n",
            "Epoch: 7\n",
            "Train Loss: 0.004419301891575257\n",
            "Train Acc: 0.9798666666666667\n",
            "Time: 94.89069271087646\n",
            "Epoch: 8\n",
            "Train Loss: 0.004165172279067338\n",
            "Train Acc: 0.9815666666666667\n",
            "Time: 96.27680349349976\n",
            "Epoch: 9\n",
            "Train Loss: 0.003881313017755747\n",
            "Train Acc: 0.9831833333333333\n",
            "Time: 96.3009831905365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_net():\n",
        "  net_4.eval()                         # evaluation mode\n",
        "  test_acc = test_samples = 0\n",
        "  T = 20\n",
        "  start_time = time.time()\n",
        "\n",
        "  with torch.no_grad():                # no gradients for speed / memory\n",
        "      for img, label in test_loader:\n",
        "          img,  label  = img.to(device), label.to(device)\n",
        "\n",
        "\n",
        "          # ----- forward (AMP optional) -----\n",
        "          with amp.autocast('cuda'):                  # works even if scaler is None\n",
        "              out_fr = 0.\n",
        "              for t in range(T):\n",
        "                  encoded_img = encoder(img)              # or let net handle the loop\n",
        "                  out_fr += net_4(encoded_img)\n",
        "              out_fr = out_fr / T              # average firing rate\n",
        "\n",
        "          # ----- metrics -----\n",
        "          test_samples += label.size(0)\n",
        "          test_acc     += (out_fr.argmax(1) == label).sum().item()\n",
        "\n",
        "          functional.reset_net(net_4)          # clear membranes for next batch\n",
        "\n",
        "  print(f\"Test Acc: {test_acc / test_samples:.4f}\")\n",
        "  print(f\"Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "test_net()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHsVIII5LR4H",
        "outputId": "d484552a-fc6c-4847-f885-fbe01f6f3991"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.9726\n",
            "Time: 6.22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = 'best_model_net_4.pth'\n",
        "torch.save({\n",
        "    'model_state_dict': net_4.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': epochs}, SAVE_PATH)\n",
        "print(\"saved to\", SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n6ougWPQrL_",
        "outputId": "9b09f34e-2e26-4bd8-9f16-b4f48366ea07"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to best_model_net_4.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dF2bqBYDRTJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}